/**
 * GPT Lama Client for AI Mentor
 * 
 * Integration with GPT Lama API for AI mentorship features
 */

import botEnv from '@/lib/config/bot-env';
import { logError } from '@/lib/logger';

export interface GptLamaConfig {
    model: string;
    temperature: number;
    top_p: number;
    max_tokens: number;
    system_prompt: string;
}

const DEFAULT_CONFIG: GptLamaConfig = {
    model: botEnv.GPT_LAMA_MODEL,
    temperature: 0.7,
    top_p: 0.9,
    max_tokens: 500,
    system_prompt: `–¢—ã - expert programming mentor –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã VibeStudy. –¢–≤–æ—è —Ä–æ–ª—å:

1. –û–±—ä—è—Å–Ω—è—Ç—å –∫–æ–¥ —á–µ—Ç–∫–æ –∏ –∫—Ä–∞—Ç–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
2. –ü–æ–º–æ–≥–∞—Ç—å —Å –æ—Ç–ª–∞–¥–∫–æ–π –æ—à–∏–±–æ–∫ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–º–∏ —Å–æ–≤–µ—Ç–∞–º–∏
3. –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–æ–¥–∞
4. –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø–æ–¥ —É—Ä–æ–≤–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
5. –ü–æ–æ—â—Ä—è—Ç—å –æ–±—É—á–µ–Ω–∏–µ, –Ω–µ –¥–∞–≤–∞—è –ø—Ä—è–º—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è
6. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫, –∏–∑–±–µ–≥–∞—Ç—å –∂–∞—Ä–≥–æ–Ω–∞ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ
7. –ü—Ä–∏–≤–æ–¥–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
8. –ë—ã—Ç—å –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º

–í–ê–ñ–ù–û: –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–æ–º–æ–≥–∞–π —Å–æ —Å–ø–∏—Å—ã–≤–∞–Ω–∏–µ–º. –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–∏.

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (–º–∞–∫—Å–∏–º—É–º 200 —Å–ª–æ–≤), –∏—Å–ø–æ–ª—å–∑—É–π emoji –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏.`,
};

// Simple in-memory cache
const cache = new Map<string, { response: string; timestamp: number }>();
const CACHE_TTL = 24 * 60 * 60 * 1000; // 24 hours

export class GptLamaClient {
    private config: GptLamaConfig;
    private apiKey: string;
    private apiUrl: string;

    constructor(config: Partial<GptLamaConfig> = {}) {
        this.config = { ...DEFAULT_CONFIG, ...config };
        this.apiKey = botEnv.GPT_LAMA_API_KEY;
        this.apiUrl = botEnv.GPT_LAMA_API_URL;
    }

    /**
     * Query GPT Lama API
     */
    async query(userMessage: string, cacheKey?: string): Promise<string> {
        // Check cache first
        if (cacheKey) {
            const cached = cache.get(cacheKey);
            if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
                console.log(`üì¶ Cache hit for: ${cacheKey.substring(0, 30)}...`);
                return cached.response;
            }
        }

        if (!this.apiKey) {
            return '‚ö†Ô∏è AI Mentor –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.';
        }

        try {
            const response = await fetch(`${this.apiUrl}/chat/completions`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${this.apiKey}`,
                },
                body: JSON.stringify({
                    model: this.config.model,
                    messages: [
                        {
                            role: 'system',
                            content: this.config.system_prompt,
                        },
                        {
                            role: 'user',
                            content: userMessage,
                        },
                    ],
                    temperature: this.config.temperature,
                    top_p: this.config.top_p,
                    max_tokens: this.config.max_tokens,
                }),
                signal: AbortSignal.timeout(30000), // 30 sec timeout
            });

            if (!response.ok) {
                const error = await response.text();
                throw new Error(`GPT Lama API error: ${response.status} - ${error}`);
            }

            const data = await response.json();
            const answer = data.choices?.[0]?.message?.content;

            if (!answer) {
                throw new Error('Empty response from GPT Lama');
            }

            // Cache the response
            if (cacheKey) {
                cache.set(cacheKey, {
                    response: answer,
                    timestamp: Date.now(),
                });
            }

            return answer;
        } catch (error) {
            logError('GPT Lama query failed', error as Error, { component: 'gpt-lama' });

            if (error instanceof Error && error.name === 'AbortError') {
                return '‚è±Ô∏è –ó–∞–ø—Ä–æ—Å –∑–∞–Ω—è–ª —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –≤–æ–ø—Ä–æ—Å.';
            }

            return '‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç AI Mentor. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.';
        }
    }

    /**
     * Explain code
     */
    async explainCode(code: string, language: string): Promise<string> {
        const message = `–û–±—ä—è—Å–Ω–∏ —ç—Ç–æ—Ç –∫–æ–¥ –Ω–∞ ${language}:\n\n\`\`\`${language}\n${code}\n\`\`\``;
        const cacheKey = `explain:${Buffer.from(code).toString('base64').slice(0, 32)}`;
        return this.query(message, cacheKey);
    }

    /**
     * Debug error
     */
    async debugError(error: string, context?: string): Promise<string> {
        const message = `–ü–æ–º–æ–≥–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è —Å —ç—Ç–æ–π –æ—à–∏–±–∫–æ–π: ${error}${context ? `\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: ${context}` : ''}`;
        const cacheKey = `debug:${Buffer.from(error).toString('base64').slice(0, 32)}`;
        return this.query(message, cacheKey);
    }

    /**
     * Answer concept question
     */
    async answerConcept(concept: string, language?: string): Promise<string> {
        const message = `–û–±—ä—è—Å–Ω–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏—é "${concept}"${language ? ` –≤ ${language}` : ''} –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏.`;
        const cacheKey = `concept:${Buffer.from(concept).toString('base64').slice(0, 32)}`;
        return this.query(message, cacheKey);
    }

    /**
     * Get hint for task
     */
    async getHint(taskDescription: string, language: string): Promise<string> {
        const message = `–î–∞–π –Ω–µ–±–æ–ª—å—à—É—é –ø–æ–¥—Å–∫–∞–∑–∫—É –¥–ª—è –∑–∞–¥–∞—á–∏ (–ù–ï —Ä–µ—à–µ–Ω–∏–µ!):\n\n${taskDescription}\n\n–Ø–∑—ã–∫: ${language}`;
        return this.query(message); // Don't cache hints
    }

    /**
     * General question
     */
    async ask(question: string): Promise<string> {
        return this.query(question);
    }
}

// Singleton instance
const gptLamaClient = new GptLamaClient();

export default gptLamaClient;
